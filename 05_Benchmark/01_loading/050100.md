---
title: Chargement de fichier
short_title: Parquet vs CSV
authors: 
    - name: Thierry HUET
      affiliations: 
        - APERTO-NOTA
      email: thierry.huet@aperto-nota.fr
subject: Mode opératoire
exports: 
  - format: pdf
    language: fr
    template: lapreprint
    date: 2025-01-08
---

# Contexte
Le chargement de données en base de données est essentiel pour l’analyse et la manipulation des données. Ce processus consiste à importer des données dans une base de données existante ou à créer une nouvelle base à partir de données externes.

Face à des volumes de données souvent très importants, il est crucial d'adopter une approche efficace. Cela inclut le choix du format de fichier approprié, la définition de la structure de la base de données et la gestion des erreurs lors du chargement.

Le format de fichier joue un rôle déterminant dans la manière dont les données sont stockées. Les formats couramment utilisés pour le chargement de données incluent CSV, Excel, JSON et SQL. Récemment, un nouveau format a fait son apparition : le format Parquet.

Notre objectif est de comparer ces formats de fichier afin de déterminer lequel est le plus adapté pour le chargement de données en base de données en tenant compte principalement de la taille des fichiers d'entrée.

# Principe
## Prérequis
- Base de données PostgreSQL 16
- Python 3.9 ou ultérieur
- psycopg2 pour la connexion à la base de données PostgreSQL
- pandas pour le traitement des données
- openpyxl pour la lecture et l'écriture de fichiers Excel

Les traitements seront effectués sur un MacBook Pro M1 avec 16 Go de RAM, où la base de données et Python sont installés localement.


# Mode opératoire
## Préparation des données
Rien de tel que la base de données des entreprises françaises pour réaliser ce type de tests. Elle contient environ 90M de lignes et mis à jour régulièrement par l'INSEE.
### Chargement des données

::: shell
curl -XGET -L https://www.data.gouv.fr/fr/datasets/r/88fbb6b4-0320-443e-b739-b4376a012c32 -o StockEtablissementHistorique_utf8.zip
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   341  100   341    0     0    618      0 --:--:-- --:--:-- --:--:--   618
100 1079M  100 1079M    0     0  2110k      0  0:08:43  0:08:43 --:--:-- 1959k

time unzip StockEtablissementHistorique_utf8.zip
Archive:  StockEtablissementHistorique_utf8.zip
  inflating: StockEtablissementHistorique_utf8.csv  
unzip StockEtablissementHistorique_utf8.zip  35,24s user 1,98s system 89% cpu 41,443 total

wc -l StockEtablissementHistorique_utf8.csv 
 88542962 StockEtablissementHistorique_utf8.csv
:::
### Préparation des données
Découpage du fichier sous forme de lots de 50_000 lignes. Export au format CSV, SQL, Excel, JSON et parquet. Noter le temps de préparation. Il est souvent négligé mais peut être conséquent (réfléchir à l'ACV de la donnée)
:::shell
python3 prepa_files.py
2025-01-08 11:38:26,179 - INFO - Chargement du fichier...
2025-01-08 11:42:37,331 - INFO - Fichier chargé...
...

:::
Comme supposé, les délais de génération/stockage des données varie avec le type de fichier. 

:::{image} img/sauvegarde.png
:alt: Durée de sauvegarde/taille de fichiers CSV ou Parquet
:align: center
:width: 75%
:::

### Importation des données

# Résultats

# En Conclusion

:::{include} 99_complements.md
:start-at: project
:end-before: references
:lineno-match:
:::